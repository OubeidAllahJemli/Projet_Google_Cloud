{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5f7d83-978e-47e2-8a34-0a111bb530a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:01:59.256752Z",
     "iopub.status.busy": "2025-12-28T15:01:59.256293Z",
     "iopub.status.idle": "2025-12-28T15:02:00.396915Z",
     "shell.execute_reply": "2025-12-28T15:02:00.394465Z",
     "shell.execute_reply.started": "2025-12-28T15:01:59.256710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "client = bigquery.Client(project=\"students-group2\")\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbe91c8-808e-4bf1-90f0-93002be0e1e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:02:16.939161Z",
     "iopub.status.busy": "2025-12-28T15:02:16.938452Z",
     "iopub.status.idle": "2025-12-28T15:02:20.131070Z",
     "shell.execute_reply": "2025-12-28T15:02:20.128986Z",
     "shell.execute_reply.started": "2025-12-28T15:02:16.939115Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from BigQuery...\n",
      "‚úì Loaded 105,339 ratings\n",
      "‚úì Loaded 10,329 movies\n",
      "‚úì Train: 84,271 ratings, Test: 21,068 ratings\n",
      "‚úì User-item matrix: (668, 9565)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data\n",
    "print(\"Loading data from BigQuery...\")\n",
    "\n",
    "# Load ratings\n",
    "query_ratings = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `master-ai-cloud.MoviePlatform.ratings`\n",
    "\"\"\"\n",
    "df_ratings = client.query(query_ratings).to_dataframe()\n",
    "print(f\"‚úì Loaded {len(df_ratings):,} ratings\")\n",
    "\n",
    "# Load movies\n",
    "query_movies = \"\"\"\n",
    "SELECT movieId, title, genres\n",
    "FROM `master-ai-cloud.MoviePlatform.movies`\n",
    "\"\"\"\n",
    "df_movies = client.query(query_movies).to_dataframe()\n",
    "print(f\"‚úì Loaded {len(df_movies):,} movies\")\n",
    "\n",
    "# Create train/test split (same split for both models)\n",
    "train_df, test_df = train_test_split(df_ratings, test_size=0.2, random_state=42)\n",
    "print(f\"‚úì Train: {len(train_df):,} ratings, Test: {len(test_df):,} ratings\")\n",
    "\n",
    "# Create user-item matrix (needed for both models)\n",
    "user_item_matrix = train_df.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating'\n",
    ").fillna(0)\n",
    "print(f\"‚úì User-item matrix: {user_item_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854b0e94-cd7f-4b68-ac84-4ab9114447e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:13:00.424632Z",
     "iopub.status.busy": "2025-12-28T15:13:00.424128Z",
     "iopub.status.idle": "2025-12-28T15:13:00.466393Z",
     "shell.execute_reply": "2025-12-28T15:13:00.464904Z",
     "shell.execute_reply.started": "2025-12-28T15:13:00.424594Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOCATING MODEL FILES\n",
      "======================================================================\n",
      "\n",
      "Current working directory: /home/jupyter/OubeidAllah_Ghassen/AI_On_The_Cloud/notebooks\n",
      "‚ùå Relative path not found: OubeidAllah_Ghassen/AI_On_The_Cloud/Ghassens_models\n",
      "\n",
      "üîç Searching for Ghassens_models folder...\n",
      "‚úÖ Found 1 location(s):\n",
      "   /home/jupyter/OubeidAllah_Ghassen/AI_On_The_Cloud/Ghassens_models\n",
      "   ‚úÖ This one has model files!\n",
      "\n",
      "üìÇ Using model directory: /home/jupyter/OubeidAllah_Ghassen/AI_On_The_Cloud/Ghassens_models\n",
      "üìç Absolute path: /home/jupyter/OubeidAllah_Ghassen/AI_On_The_Cloud/Ghassens_models\n",
      "\n",
      "‚úì Checking for required files:\n",
      "   ‚úÖ U.pkl                     (0.05 MB)\n",
      "   ‚úÖ sigma.pkl                 (0.00 MB)\n",
      "   ‚úÖ Vt.pkl                    (0.73 MB)\n",
      "   ‚úÖ user_means.pkl            (0.01 MB)\n",
      "   ‚úÖ movie_ids.pkl             (0.03 MB)\n",
      "   ‚úÖ movies_metadata.pkl       (0.44 MB)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.5: Find Your Model Files\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOCATING MODEL FILES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check current directory\n",
    "print(f\"\\nCurrent working directory: {os.getcwd()}\")\n",
    "\n",
    "# Try the relative path first\n",
    "relative_path = 'OubeidAllah_Ghassen/AI_On_The_Cloud/Ghassens_models'\n",
    "if os.path.exists(relative_path):\n",
    "    print(f\"‚úÖ Found models at relative path: {relative_path}\")\n",
    "    svd_model_dir = relative_path\n",
    "else:\n",
    "    print(f\"‚ùå Relative path not found: {relative_path}\")\n",
    "    \n",
    "    # Search for the folder\n",
    "    print(\"\\nüîç Searching for Ghassens_models folder...\")\n",
    "    result = subprocess.run(\n",
    "        ['find', '/home/jupyter', '-name', 'Ghassens_models', '-type', 'd'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.stdout:\n",
    "        found_paths = result.stdout.strip().split('\\n')\n",
    "        print(f\"‚úÖ Found {len(found_paths)} location(s):\")\n",
    "        for path in found_paths:\n",
    "            print(f\"   {path}\")\n",
    "            # Check if it has the model files\n",
    "            if os.path.exists(os.path.join(path, 'U.pkl')):\n",
    "                svd_model_dir = path\n",
    "                print(f\"   ‚úÖ This one has model files!\")\n",
    "        \n",
    "        if 'svd_model_dir' not in locals():\n",
    "            svd_model_dir = found_paths[0]\n",
    "    else:\n",
    "        print(\"‚ùå Could not find Ghassens_models folder\")\n",
    "        print(\"\\nPlease run your model training notebook (03_matrix_factorization_model.ipynb)\")\n",
    "        print(\"and save the model first!\")\n",
    "        raise FileNotFoundError(\"Model files not found. Please train and save the model first.\")\n",
    "\n",
    "# Verify the files exist\n",
    "print(f\"\\nüìÇ Using model directory: {svd_model_dir}\")\n",
    "print(f\"üìç Absolute path: {os.path.abspath(svd_model_dir)}\")\n",
    "\n",
    "required_files = ['U.pkl', 'sigma.pkl', 'Vt.pkl', 'user_means.pkl', 'movie_ids.pkl', 'movies_metadata.pkl']\n",
    "print(\"\\n‚úì Checking for required files:\")\n",
    "for file in required_files:\n",
    "    filepath = os.path.join(svd_model_dir, file)\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"   ‚úÖ {file:<25} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {file:<25} MISSING!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7d1281-757f-47bd-a714-8567f0e911dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:13:42.461014Z",
     "iopub.status.busy": "2025-12-28T15:13:42.460204Z",
     "iopub.status.idle": "2025-12-28T15:13:42.584340Z",
     "shell.execute_reply": "2025-12-28T15:13:42.582468Z",
     "shell.execute_reply.started": "2025-12-28T15:13:42.460968Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING SVD MATRIX FACTORIZATION MODEL\n",
      "======================================================================\n",
      "Loading from: /home/jupyter/OubeidAllah_Ghassen/AI_On_The_Cloud/Ghassens_models\n",
      "‚úì Loaded U matrix: (668, 10)\n",
      "‚úì Loaded Sigma matrix: (10, 10)\n",
      "‚úì Loaded Vt matrix: (10, 9565)\n",
      "‚úì Loaded user means: 668\n",
      "\n",
      "Generating predictions...\n",
      "‚úì SVD predictions generated: (668, 9565)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load SVD Model (FIXED)\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING SVD MATRIX FACTORIZATION MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# svd_model_dir is already set by Cell 2.5\n",
    "print(f\"Loading from: {svd_model_dir}\")\n",
    "\n",
    "# Load SVD components\n",
    "try:\n",
    "    with open(os.path.join(svd_model_dir, 'U.pkl'), 'rb') as f:\n",
    "        U = pickle.load(f)\n",
    "    print(f\"‚úì Loaded U matrix: {U.shape}\")\n",
    "\n",
    "    with open(os.path.join(svd_model_dir, 'sigma.pkl'), 'rb') as f:\n",
    "        sigma = pickle.load(f)\n",
    "    print(f\"‚úì Loaded Sigma matrix: {sigma.shape}\")\n",
    "\n",
    "    with open(os.path.join(svd_model_dir, 'Vt.pkl'), 'rb') as f:\n",
    "        Vt = pickle.load(f)\n",
    "    print(f\"‚úì Loaded Vt matrix: {Vt.shape}\")\n",
    "\n",
    "    with open(os.path.join(svd_model_dir, 'user_means.pkl'), 'rb') as f:\n",
    "        user_means_svd = pickle.load(f)\n",
    "    print(f\"‚úì Loaded user means: {len(user_means_svd)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n‚ùå ERROR: Could not load model files!\")\n",
    "    print(f\"Missing file: {e}\")\n",
    "    print(\"\\nüí° Solution:\")\n",
    "    print(\"1. Go to your 03_matrix_factorization_model.ipynb notebook\")\n",
    "    print(\"2. Run all cells to train the model\")\n",
    "    print(\"3. Run the save cell (Cell 10) to save model files\")\n",
    "    print(\"4. Then come back and run this comparison notebook\")\n",
    "    raise\n",
    "\n",
    "# Define SVD prediction function\n",
    "def predict_svd(U, sigma, Vt, user_means, train_matrix):\n",
    "    \"\"\"Generate predictions using SVD\"\"\"\n",
    "    R_pred = U @ sigma @ Vt + user_means.reshape(-1, 1)\n",
    "    R_pred = np.clip(R_pred, 0.5, 5.0)\n",
    "    return pd.DataFrame(R_pred, index=train_matrix.index, columns=train_matrix.columns)\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "svd_predictions = predict_svd(U, sigma, Vt, user_means_svd, user_item_matrix)\n",
    "print(f\"‚úì SVD predictions generated: {svd_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4782c70-f90a-40cb-8feb-04622babdece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:14:15.714513Z",
     "iopub.status.busy": "2025-12-28T15:14:15.714058Z",
     "iopub.status.idle": "2025-12-28T15:14:19.516006Z",
     "shell.execute_reply": "2025-12-28T15:14:19.514597Z",
     "shell.execute_reply.started": "2025-12-28T15:14:15.714467Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING ITEM-BASED COLLABORATIVE FILTERING MODEL\n",
      "======================================================================\n",
      "‚úì Loaded item similarity matrix: (10325, 10325)\n",
      "‚úì Item-similarity prediction function loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load/Compute Item-Similarity Model\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING ITEM-BASED COLLABORATIVE FILTERING MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Try to load pre-computed similarity matrix\n",
    "item_sim_model_dir = '../models/item_similarity_2'  # Adjust this path\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(item_sim_model_dir, 'item_similarity_with_confidence_weighting.pkl'), 'rb') as f:\n",
    "        item_similarity_df = pickle.load(f)\n",
    "    print(f\"‚úì Loaded item similarity matrix: {item_similarity_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  Pre-trained item similarity not found. Computing from scratch...\")\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    item_matrix = user_item_matrix.T\n",
    "    item_similarity = cosine_similarity(item_matrix)\n",
    "    item_similarity_df = pd.DataFrame(\n",
    "        item_similarity,\n",
    "        index=item_matrix.index,\n",
    "        columns=item_matrix.index\n",
    "    )\n",
    "    print(f\"‚úì Computed item similarity matrix: {item_similarity_df.shape}\")\n",
    "\n",
    "# Define item-similarity prediction function\n",
    "def predict_item_similarity(user_id, movie_id, user_item_matrix, item_similarity_df, k=50):\n",
    "    \"\"\"\n",
    "    Predict rating for a user-movie pair using item-based CF\n",
    "    \"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return 3.5\n",
    "    \n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    rated_movies = user_ratings[user_ratings > 0]\n",
    "    \n",
    "    if len(rated_movies) == 0:\n",
    "        return 3.5\n",
    "    \n",
    "    if movie_id not in item_similarity_df.index:\n",
    "        return rated_movies.mean()\n",
    "    \n",
    "    similarities = item_similarity_df[movie_id]\n",
    "    relevant_similarities = similarities[rated_movies.index]\n",
    "    top_k = relevant_similarities.nlargest(min(k, len(relevant_similarities)))\n",
    "    \n",
    "    if top_k.sum() == 0:\n",
    "        return rated_movies.mean()\n",
    "    \n",
    "    weighted_sum = sum(top_k[mid] * rated_movies[mid] for mid in top_k.index)\n",
    "    prediction = weighted_sum / top_k.sum()\n",
    "    \n",
    "    return np.clip(prediction, 0.5, 5.0)\n",
    "\n",
    "print(\"‚úì Item-similarity prediction function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d6d81e-3351-4de1-997f-e274b796f909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:15:43.167849Z",
     "iopub.status.busy": "2025-12-28T15:15:43.166698Z",
     "iopub.status.idle": "2025-12-28T15:15:56.067610Z",
     "shell.execute_reply": "2025-12-28T15:15:56.066114Z",
     "shell.execute_reply.started": "2025-12-28T15:15:43.167800Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUATING PREDICTION ACCURACY\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£  Evaluating SVD Matrix Factorization...\n",
      "  Samples evaluated: 20,239\n",
      "  RMSE: 0.9100\n",
      "  MAE:  0.7018\n",
      "  Time: 1.61s\n",
      "\n",
      "2Ô∏è‚É£  Evaluating Item-Based Collaborative Filtering...\n",
      "  Samples evaluated: 5,000\n",
      "  RMSE: 0.8786\n",
      "  MAE:  0.6706\n",
      "  Time: 11.27s\n",
      "\n",
      "3Ô∏è‚É£  Baseline (Always predict average)...\n",
      "  Baseline prediction: 3.52\n",
      "  RMSE: 1.0441\n",
      "  MAE:  0.8340\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Evaluate Both Models\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATING PREDICTION ACCURACY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Evaluate SVD\n",
    "print(\"\\n1Ô∏è‚É£  Evaluating SVD Matrix Factorization...\")\n",
    "svd_test_preds = []\n",
    "svd_test_actuals = []\n",
    "svd_start = time.time()\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    user_id = row['userId']\n",
    "    movie_id = row['movieId']\n",
    "    actual = row['rating']\n",
    "    \n",
    "    if user_id in svd_predictions.index and movie_id in svd_predictions.columns:\n",
    "        pred = svd_predictions.loc[user_id, movie_id]\n",
    "        svd_test_preds.append(pred)\n",
    "        svd_test_actuals.append(actual)\n",
    "\n",
    "svd_time = time.time() - svd_start\n",
    "\n",
    "svd_rmse = np.sqrt(mean_squared_error(svd_test_actuals, svd_test_preds))\n",
    "svd_mae = mean_absolute_error(svd_test_actuals, svd_test_preds)\n",
    "\n",
    "print(f\"  Samples evaluated: {len(svd_test_preds):,}\")\n",
    "print(f\"  RMSE: {svd_rmse:.4f}\")\n",
    "print(f\"  MAE:  {svd_mae:.4f}\")\n",
    "print(f\"  Time: {svd_time:.2f}s\")\n",
    "\n",
    "# Evaluate Item Similarity\n",
    "print(\"\\n2Ô∏è‚É£  Evaluating Item-Based Collaborative Filtering...\")\n",
    "item_test_preds = []\n",
    "item_test_actuals = []\n",
    "item_start = time.time()\n",
    "\n",
    "# Sample for faster evaluation\n",
    "test_sample = test_df.sample(min(5000, len(test_df)), random_state=42)\n",
    "\n",
    "for idx, row in test_sample.iterrows():\n",
    "    user_id = row['userId']\n",
    "    movie_id = row['movieId']\n",
    "    actual = row['rating']\n",
    "    \n",
    "    pred = predict_item_similarity(user_id, movie_id, user_item_matrix, item_similarity_df, k=50)\n",
    "    item_test_preds.append(pred)\n",
    "    item_test_actuals.append(actual)\n",
    "\n",
    "item_time = time.time() - item_start\n",
    "\n",
    "item_rmse = np.sqrt(mean_squared_error(item_test_actuals, item_test_preds))\n",
    "item_mae = mean_absolute_error(item_test_actuals, item_test_preds)\n",
    "\n",
    "print(f\"  Samples evaluated: {len(item_test_preds):,}\")\n",
    "print(f\"  RMSE: {item_rmse:.4f}\")\n",
    "print(f\"  MAE:  {item_mae:.4f}\")\n",
    "print(f\"  Time: {item_time:.2f}s\")\n",
    "\n",
    "# Baseline\n",
    "print(\"\\n3Ô∏è‚É£  Baseline (Always predict average)...\")\n",
    "baseline_pred = df_ratings['rating'].mean()\n",
    "baseline_preds = [baseline_pred] * len(svd_test_actuals)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(svd_test_actuals, baseline_preds))\n",
    "baseline_mae = mean_absolute_error(svd_test_actuals, baseline_preds)\n",
    "\n",
    "print(f\"  Baseline prediction: {baseline_pred:.2f}\")\n",
    "print(f\"  RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"  MAE:  {baseline_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cd98f8d-ecd5-41c6-9ea5-01e7e5edc573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T15:15:56.070446Z",
     "iopub.status.busy": "2025-12-28T15:15:56.069844Z",
     "iopub.status.idle": "2025-12-28T15:15:56.096633Z",
     "shell.execute_reply": "2025-12-28T15:15:56.094968Z",
     "shell.execute_reply.started": "2025-12-28T15:15:56.070398Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREDICTION ACCURACY COMPARISON\n",
      "======================================================================\n",
      "\n",
      "                   Model   RMSE    MAE Within ¬±0.5‚òÖ Within ¬±1.0‚òÖ Time (s)\n",
      "      Baseline (Average) 1.0441 0.8340          N/A          N/A   < 0.01\n",
      "           Item-Based CF 0.8786 0.6706        47.0%        78.3%    11.27\n",
      "SVD Matrix Factorization 0.9100 0.7018        44.7%        75.6%     1.61\n",
      "\n",
      "======================================================================\n",
      "üèÜ WINNER ANALYSIS\n",
      "======================================================================\n",
      "‚úÖ Item-Based Collaborative Filtering WINS!\n",
      "   RMSE improvement: 3.5% better than SVD\n",
      "\n",
      "   Both models beat baseline (RMSE=1.0441)\n",
      "   SVD beats baseline by: 12.8%\n",
      "   Item-CF beats baseline by: 15.9%\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Comparison Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREDICTION ACCURACY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate accuracy percentages\n",
    "svd_errors = np.abs(np.array(svd_test_preds) - np.array(svd_test_actuals))\n",
    "svd_within_half = (svd_errors <= 0.5).sum() / len(svd_errors) * 100\n",
    "svd_within_one = (svd_errors <= 1.0).sum() / len(svd_errors) * 100\n",
    "\n",
    "item_errors = np.abs(np.array(item_test_preds) - np.array(item_test_actuals))\n",
    "item_within_half = (item_errors <= 0.5).sum() / len(item_errors) * 100\n",
    "item_within_one = (item_errors <= 1.0).sum() / len(item_errors) * 100\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Model': [\n",
    "        'Baseline (Average)',\n",
    "        'Item-Based CF',\n",
    "        'SVD Matrix Factorization'\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        f\"{baseline_rmse:.4f}\",\n",
    "        f\"{item_rmse:.4f}\",\n",
    "        f\"{svd_rmse:.4f}\"\n",
    "    ],\n",
    "    'MAE': [\n",
    "        f\"{baseline_mae:.4f}\",\n",
    "        f\"{item_mae:.4f}\",\n",
    "        f\"{svd_mae:.4f}\"\n",
    "    ],\n",
    "    'Within ¬±0.5‚òÖ': [\n",
    "        'N/A',\n",
    "        f\"{item_within_half:.1f}%\",\n",
    "        f\"{svd_within_half:.1f}%\"\n",
    "    ],\n",
    "    'Within ¬±1.0‚òÖ': [\n",
    "        'N/A',\n",
    "        f\"{item_within_one:.1f}%\",\n",
    "        f\"{svd_within_one:.1f}%\"\n",
    "    ],\n",
    "    'Time (s)': [\n",
    "        '< 0.01',\n",
    "        f\"{item_time:.2f}\",\n",
    "        f\"{svd_time:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Winner analysis\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèÜ WINNER ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if svd_rmse < item_rmse:\n",
    "    improvement = (item_rmse - svd_rmse) / item_rmse * 100\n",
    "    print(f\"‚úÖ SVD Matrix Factorization WINS!\")\n",
    "    print(f\"   RMSE improvement: {improvement:.1f}% better than Item-Based CF\")\n",
    "else:\n",
    "    improvement = (svd_rmse - item_rmse) / svd_rmse * 100\n",
    "    print(f\"‚úÖ Item-Based Collaborative Filtering WINS!\")\n",
    "    print(f\"   RMSE improvement: {improvement:.1f}% better than SVD\")\n",
    "\n",
    "print(f\"\\n   Both models beat baseline (RMSE={baseline_rmse:.4f})\")\n",
    "print(f\"   SVD beats baseline by: {(baseline_rmse - svd_rmse)/baseline_rmse*100:.1f}%\")\n",
    "print(f\"   Item-CF beats baseline by: {(baseline_rmse - item_rmse)/baseline_rmse*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d55be0-30b4-412f-8162-496ece4687ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Comparison Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREDICTION ACCURACY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate accuracy percentages\n",
    "svd_errors = np.abs(np.array(svd_test_preds) - np.array(svd_test_actuals))\n",
    "svd_within_half = (svd_errors <= 0.5).sum() / len(svd_errors) * 100\n",
    "svd_within_one = (svd_errors <= 1.0).sum() / len(svd_errors) * 100\n",
    "\n",
    "item_errors = np.abs(np.array(item_test_preds) - np.array(item_test_actuals))\n",
    "item_within_half = (item_errors <= 0.5).sum() / len(item_errors) * 100\n",
    "item_within_one = (item_errors <= 1.0).sum() / len(item_errors) * 100\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Model': [\n",
    "        'Baseline (Average)',\n",
    "        'Item-Based CF',\n",
    "        'SVD Matrix Factorization'\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        f\"{baseline_rmse:.4f}\",\n",
    "        f\"{item_rmse:.4f}\",\n",
    "        f\"{svd_rmse:.4f}\"\n",
    "    ],\n",
    "    'MAE': [\n",
    "        f\"{baseline_mae:.4f}\",\n",
    "        f\"{item_mae:.4f}\",\n",
    "        f\"{svd_mae:.4f}\"\n",
    "    ],\n",
    "    'Within ¬±0.5‚òÖ': [\n",
    "        'N/A',\n",
    "        f\"{item_within_half:.1f}%\",\n",
    "        f\"{svd_within_half:.1f}%\"\n",
    "    ],\n",
    "    'Within ¬±1.0‚òÖ': [\n",
    "        'N/A',\n",
    "        f\"{item_within_one:.1f}%\",\n",
    "        f\"{svd_within_one:.1f}%\"\n",
    "    ],\n",
    "    'Time (s)': [\n",
    "        '< 0.01',\n",
    "        f\"{item_time:.2f}\",\n",
    "        f\"{svd_time:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Winner analysis\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèÜ WINNER ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if svd_rmse < item_rmse:\n",
    "    improvement = (item_rmse - svd_rmse) / item_rmse * 100\n",
    "    print(f\"‚úÖ SVD Matrix Factorization WINS!\")\n",
    "    print(f\"   RMSE improvement: {improvement:.1f}% better than Item-Based CF\")\n",
    "else:\n",
    "    improvement = (svd_rmse - item_rmse) / svd_rmse * 100\n",
    "    print(f\"‚úÖ Item-Based Collaborative Filtering WINS!\")\n",
    "    print(f\"   RMSE improvement: {improvement:.1f}% better than SVD\")\n",
    "\n",
    "print(f\"\\n   Both models beat baseline (RMSE={baseline_rmse:.4f})\")\n",
    "print(f\"   SVD beats baseline by: {(baseline_rmse - svd_rmse)/baseline_rmse*100:.1f}%\")\n",
    "print(f\"   Item-CF beats baseline by: {(baseline_rmse - item_rmse)/baseline_rmse*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
